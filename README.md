# 100+ LLM Questions and Answers Every AI Engineer Needs to Know

This repository contains a comprehensive list of questions and answers that every AI engineer should be familiar with. The questions are categorized into various topics to help you focus on specific areas of interest.

## Table of Contents

1. [Prompt Engineering & Basics of LLM](#1-prompt-engineering--basics-of-llm)
2. [Retrieval Augmented Generation (RAG)](#2-retrieval-augmented-generation-rag)
3. [Chunking](#3-chunking)
4. [Embedding Models](#4-embedding-models)
5. [Internal Working of Vector Databases](#5-internal-working-of-vector-databases)
6. [Advanced Search Algorithms](#6-advanced-search-algorithms)
7. [Language Models Internal Working](#7-language-models-internal-working)
8. [Supervised Fine-Tuning of LLM](#8-supervised-fine-tuning-of-llm)
9. [Preference Alignment (RLHF/DPO)](#9-preference-alignment-rlhfdpo)
10. [Evaluation of LLM System](#10-evaluation-of-llm-system)
11. [Hallucination Control Techniques](#11-hallucination-control-techniques)
12. [Deployment of LLM](#12-deployment-of-llm)
13. [Agent-Based System](#13-agent-based-system)
14. [Prompt Hacking](#14-prompt-hacking)
15. [Miscellaneous](#15-miscellaneous)

## Topics

### 1. Prompt Engineering & Basics of LLM

- Questions related to the fundamentals of large language models, prompt engineering, and effective usage techniques.

### 2. Retrieval Augmented Generation (RAG)

- Insights into combining retrieval systems with generation models to enhance accuracy and reliability.

### 3. Chunking

- Techniques for breaking down large datasets or text into manageable pieces for processing by LLMs.

### 4. Embedding Models

- Detailed questions on vector embeddings, their applications, and how to benchmark and improve embedding models.

### 5. Internal Working of Vector Databases

- Understanding the architecture, indexing methods, and optimization strategies for vector databases.

### 6. Advanced Search Algorithms

- Exploration of search algorithms, information retrieval techniques, and evaluation metrics.

### 7. Language Models Internal Working

- In-depth questions on the internal mechanisms of language models, including self-attention, transformers, and optimization.

### 8. Supervised Fine-Tuning of LLM

- Methods and best practices for fine-tuning large language models on specific tasks or datasets.

### 9. Preference Alignment (RLHF/DPO)

- Techniques for aligning model outputs with human preferences using reinforcement learning and other methods.

### 10. Evaluation of LLM System

- Metrics and methodologies for evaluating the performance and reliability of large language models.

### 11. Hallucination Control Techniques

- Strategies to mitigate and control hallucinations in LLM outputs.

### 12. Deployment of LLM

- Best practices for deploying large language models, including optimization and scaling techniques.

### 13. Agent-Based System

- Concepts and strategies for implementing agent-based systems using LLMs.

### 14. Prompt Hacking

- Understanding prompt hacking techniques and defense mechanisms to ensure safe and reliable model outputs.

### 15. Miscellaneous

- Various advanced topics and questions that do not fit into the other categories but are essential for AI engineers.

## How to Use This Repository

- **Explore by Topic**: Navigate through the topics listed above to find questions and answers relevant to your area of interest.
- **Contribute**: If you have additional questions or answers, feel free to contribute by opening a pull request.
- **Stay Updated**: This repository is continuously updated to include the latest trends and advancements in AI.

## Contributing

We welcome contributions from the community! If you have questions or answers that you believe should be included, please follow these steps:

1. Fork the repository.
2. Create a new branch for your contribution.
3. Add your questions and answers in the appropriate topic folder.
4. Submit a pull request with a detailed description of your changes.

---